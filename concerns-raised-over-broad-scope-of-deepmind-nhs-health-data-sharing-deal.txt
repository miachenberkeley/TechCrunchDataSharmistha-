Concerns have been raised about the scope of adata-sharing agreement between Google-owned DeepMind andthe UKs National Health Service (NHS) after it was revealed the agreementcovers access to all patient data from the three London hospitals involved, rather than a more targeted subset ofdatarelating to the specific medical condition the healthcareapp in question (Streams) is focused on.Back in February DeepMindannounced acollaboration with the NHS to build an app for clinicians treating kidney disease. The company alsoacquired an existing early stage clinical task management app, called Hark, built by a team from Imperial College London  evidently with the intention of building on that base tech, but giving it a morespecific medical focus in the first instance.The Streams app aims to streamline alerts and access topatient datafor doctors and nurses working in the front-line of medical care. But it is not a general medical data alerts or messaging platform. Rather it isspecifically focused on a single use-case: detecting cases of AKI (acute kidney injury).Atthe time he announced the project, DeepMind co-founder Mustafa Suleyman saidAKI accounts for some 40,000 deaths annually in the UK  a quarter of which he said were estimated to be preventable.Streams will deliver the right data to the right clinician at exactly the right time. Really the objective here is for us to try and shift some of the 97% or so of activity in the hospital today which is reactive further towards activity which is pro-active and ultimately preventative, he said atthe launch.This of course is where our cutting edge analytics and machine learning comes in. How do you prioritize the series of alerts that go to a doctor or a nurse? How do you identifywhich personon the clinical team should be receivingthe right dataand how do you ensure theyve been followed up in good time?However, late last weekNew Scientist obtained the data-sharing agreement between DeepMind and the Royal Free NHS Trust, which operates the three hospitals, where an estimated 1.6 million patients are treatedannually.The agreementshows DeepMind Health is gainingaccess toall admissions, discharge and transfer data, accident & emergency, pathology & radiology, and critical care at these hospitals.It alsoincludes five years of historical medical records data on patients who have been treated atthe hospitals.The data-sharing agreement with DeepMind is set to run until September 29, 2017, after which the documentspecifies that all data betransferred back to the NHS trust and any residual data be destroyed.The data in question is not being stored or processed at DeepMinds office, but is rather held by a contracted third party (whose name has been redacted on the document).DeepMind staff who have undergone information governance training and signed a confidentiality agreement as part of their employment are specified as the authorised users of the data.Consent from patients who usethe Royal Free NHS Trust to havetheir data shared with the Google-owned company has been implied via the NHS Caldicott Information Governance Review regime  meaning NHS trusts do not need to explicitly seek consent to share data (although patients can opt-out of anyinformation sharing agreements with non-NHS organisations by contacting the trusts data protection officer. And assuming they know about the existence of the data-sharing agreement in the first place).Criticism of the agreement has focused on why DeepMind needs access to so much patient data, giventheir app is apparently targeted on one specific medical condition (i.e. AKI).There is also a wider critical point to consider about the trade-offs of having such a large commercial entity (DeepMinds parent, Google/Alphabet) gain access  albeit indirectly, in this particular instance  to sensitive and highly valuable (and ultimately taxpayer-funded) medical data.On the one hand its entirely possible that clinical outcomes and patient care might beimproved by the money and agility of private companies. On the other, are we as a society comfortable lettingprofit-driven companies take the leadin public health by affording themaccess to value data sets  and potentially chaining any benefits to the commercial sector for the foreseeable future?Meanwhile less well resourced public sector research efforts  which would be motivated to share any gleaned health insights more broadly  are left to labour inthe rear.One critical voice raised againstthe DeepMind data-sharing agreement is health data privacy group MedConfidential, which is particularly concerned aboutwhy Royal Free Trust data streams are being shared forall patients, rather thanjust forthose who have had kidney function tests.Phil Booth, coordinator of the group, points out that NHS data-sharing agreements require a statement of why particular data is required. So why do Google need the full data from the entire hospital?Why do they get data on everyone who has no tests done? he tellsTechCrunch. For patients who are having such tests, the patient medical history is available as part of direct care, why do they need everything else?Their answers dont add up.DeepMind declined to be interviewed on this topic, and several members of its review board did notrespond to requests for comment.Update:One of these DeepMind-appointed (but unpaid) reviewers, former MP Julian Huppert, has now responded, saying he has asked for the data scope issue to be discussed at the first panel meeting so that we can assure ourselves what data access there actually is, and how it can be used.In particular, I would want to be absolutely clear that none of this sensitive information can be used by other parts of Google, and that DeepMind stick to their commitment that privacy and security are protected at all times, he told TechCrunch.There are potentially huge advantages for all of us in improving the way our health system uses data, both so that we can have our own data used to help us faster and more efficiently, and by using aggregate data to make predictions. However, the misuse of this sensitive data can also be hugely problematic, as can the potential privacy intrusion, and I would want to maximise the benefit while minimising the risks.A spokeswoman for DeepMindprovided the following two canned statements in response to requests for an interview:Mustafa Suleyman, Co-Founder at DeepMind, said: We are working with clinicians at the Royal Free to understand how technology can best help clinicians recognise patient deterioration  in this case acute kidney injury (AKI). We have, and will always, hold ourselves to the highest possible standards of patient data protection. This data will only ever be used for the purposes of improving healthcare and will never be linked with Google accounts or products.Dominic King, a Senior Clinician Scientist at Google DeepMind said: Access to timely and relevant clinical data is essential for doctors and nurses looking for signs of patient deterioration. This work focuses on acute kidney injuries that contribute to 40,000 deaths a year in the UK, many of which are preventable. The kidney specialists who have led this work are confident that the alerts our system generates will transform outcomes for their patients. For us to generate these alerts it is necessary for us to look at a range of tests taken at different time intervals.A spokesman for the Royal Free, whichwas reachable by telephone, told TechCrunch the reason DeepMind is being provided withaccess to all patientdata is on account of AKI affecting a large proportionofpatients  and the condition not having aclear set of particular signals/symptoms associated with it, meaning early detection requires drawing ona lot of data.Acute kidney injury affects one in six patients. So its not that this is being used to treat people with specific kidney conditions. Its used to spot the likelihood of acute kidney injury occurring in any in patient. So the way it does that is not just by assessing their blood test results but looking at their patient history. Thats why they get the full patient records, he said.It is undoubtedly a rather convenient argument, for the advancement of DeepMinds AI-based ambitions, that the nature of the specific medical condition it has kicked offits healthcare app efforts with apparently requires access to all hospital patient data  even, for example, people admitted to hospital for an abortion, say, or a drugs overdose. Or someone whoarrived in A&Eafter falling on the stairs and breaking a leg.Butthe spokesman for the Royal Free Trust asserted thathanding over all data is necessary in order for the app to function effectively, in this particular instance.Its not that they specifically get abortion data [for example] its just that for a patient to be fully assessed for the likelihood of acute kidney their patient records are analyzed, he said.The point is, and the way the algorithm works, is [there isnt any one sub-set of relevant patient data]. The algorithm uses all kinds of data to make that judgement. So there isnt a clear sub-set of data that is the only thing that indicates whether somebody is about to go into acute kidney injury. Because its not just about your own personal blood test results, or your own personal anything results. Its about the type of person you are. It looks at your whole medical history and makes a judgement  and thats what makes the algorithm so effective.TechCrunchalso contacted the Royal Free Trusts patient data protection officer for comment and will update this post with any response.DeepMind confirmed it is not, at this point, performingany machine learning/AI processing onthe data it is receiving, although the company has clearly indicated it would like to do so in future. A note on its website pertaining tothis ambitionreads:[A]rtificial intelligence is not part of the early-stage pilots were announcing today. Its too early to determine where AI could be applied here, but its certainly something we are excited about for the future.The Royal Free spokesman saidit is not possible, under the current data-sharing agreement between the trust and DeepMind, for the company to apply AI technology to these data-sets and data streams.That type of processing of the data would require another agreement, he confirmed.The only thing this data is for is direct patient care, he added. It is not being used for research, or anything like that.However quite how the NHS Trust can hope to maintain control over any future AI algorithms that DeepMind might create  trainedoff of the insights it gleans from the original public data-set  is unclear.Another critical point to note here is that while private companies are being provided with access to sensitive public data sets, they are not required to be accountable for their decisions and actions to the public  hence DeepMind feeling entirely comfortable in declining multiple requests to be interviewed by the media on the topic.And as New Scientist has pointed out, if ithas nothing to hide about its use of NHS data, why so secretive? Public health data does not combine well with high-handed secrecy. Nor does the latter provide the necessary public reassurance about private sector motivations when it comes tohandling and processing hugely sensitive public data sets. So, in short, DeepMind/Google needs to learn to improve its bedside manner if it wants to win patients hearts and minds.This post was updated with additional comment