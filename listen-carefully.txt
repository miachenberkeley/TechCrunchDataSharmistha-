The way technology shapes language is fascinating. And often colloquially cringeworthy (to wit: I dont have bandwidth right now Lets take this offline Id totally swipe that). At bottom itsa reflection of how ourtools influence and shape our social interactions.The reverse is also true, of course. Technology platforms end up being moulded by their human users in ways their makers did not envisage or necessarily intend when they builtthe initial feature set and structure.Hashtags on Twitter andthe Retweet function were essentiallyuser-generated, for instance. The people with earlyaccess to an MVPgrabbed the baton and ran with it  and that combination of rough-and-ready technologyplus interested early adoptersresulted in somethingfascinating and genuinely useful beingcreated. Theres a lesson there in these times of increasinglyprescriptivealgorithms.And, yes, asacounterpoint, we have the gaming of social platforms by hate speech groups bent on using the reach of mainstream social media to amplify fringe agendas, and silence the targets of their abuse, via co-ordinated bullying. Even Twitternow thinksit needs to up its game to deal with that kind of corrosive service misuse.Stepping out from there, there are also parallel lessons to be drawnfrom how people are talking about the technology services they are interacting with.Not just in general terms  whether they like or dislike a serviceand so on; but what their more subtle linguistic choicesmight be expressing on their behalf. Reactions that might be evident in language before users areconsciously articulating theirfeelings as fully formed thoughts.One fascinating current example involves dating apps, and the use of a particularphrase  going dark to describe what happens when a match stops responding. That is to say when the signaling between two users stops because one of them stops responding, despite there having beena degree ofpriorly stated mutual interest. (One wonders how Jane Austin mighthave interrogatedsuchhingedmoments.)The developerbehind a machine-learning Tinderbot whichhacks the dating app to automatically filter potential matchesbased on theusers prior aesthetic preferences, used the phrase ina blogabout his project  noting that it was this characteristicof dating app interactions that encouraged him to add an additional feature to his bot. This feature auto-starts conversations by sending pre-set messages to test the waters. An automated interest primer if you will.Describing theauto-messaging feature, he wrote:The advantage of this? It removes the time involved in filtering new Tinder matches since a lot of people tend to drop off and go dark early in the process. Extended conversation is a strong indicator of interest.Its a pitchperfect engineers fix for what is actually a far more interesting social problem thatdating apps are exposing to a greater degree ofsocial scrutiny by increasing the frequency of/encounters with this dropping off behavior.Going dark in fact hints at a kind ofsocial breaking point whichapps are stumbling into, at the cutting edge of human emotional interactions. Its the digital equivalent of a mild snub or social slight  veryslight, given its not public and is doled out to someone you dontyet have any strong ties to.The fact these types of apps make it easier to meet new people means it necessarily follows their usersare going to encounter a higher volume ofexplicit social rejectionsthan they normally would.And so going dark is the phrase theyhave come up with to describe anantisocial byproductof using a socially catalyzing service  and, perhaps, to take some of the sting out of all those Im not/no longer interested signals.Sincedating apps enable surface connections to be made more quickly it logicallyfollows they are also responsible for more speedy social disconnections. And so the necessity to coin a phrasefor this nowmore commonlyexperienced behavior  ergo:going dark.Going dark is, in my view, a pretty great descriptor for this dating app foible, since it characterizesother users as so many pixels thatcan either light up or not, when you ping them, rather than as flesh and blood humans who have stopped responding and are therefore actively snubbing you. Which of course they (probably) are.But the point is it shows users taking a sophisticated approach to what can be very throwaway interactions  on account of these apps making it so easy to engage with randoms.In essence, the humans are defusing all the subtle disconnections thatsuch a high volume ofdigital interactions inevitably entails. After all,virtual social snubs arent really all that. And digital dating relations are necessarily cheap, given they arent (yet) deep.If there is any cause for concern here, its that going dark entering the dating app user lexicon may also signify interaction overload. That peopleare being swamped with somanysignalsthey feel unable to respond, politely or otherwise, to each and every match and so are resorting toswitching off the messaging channel to enable themto move on and keep using the app. Aka theyare taking the path of least resistance.(Silence may also be the most tactful way to say no thanks to a prospective date  rather than having to explain at length that while they seem(ed) interesting their follow upsignals have not struck such an interesting chord. Anotherexample of this sort of subtle social signaling at play in the digital space is the wayTwitter users deploythe star feature as a word-free meta-communication method. A way to say something without actually saying anything.)The underlying conceptof going dark also brings to mind thelatestBlack Mirror episode Black MirrorbeingCharlie Brookers satirical TV series which imagines how technology tools might warp our social interactions in a not-too-far-flung future.In the holiday special, screened before Christmas, a fictional story unfoldsinvolving peoplewho have had embedded cameras (called Z-Eyes) implanted intotheir eyes  which enables them to activate advanced augmented reality functions such as filtering outthe sight and soundofparticularindividuals.When activated, insteadof a person they see a fuzzy silhouette and hear garbled noises rather than actualwords. Brooker callsthis feature being blocked. Its like an extreme manifestation of going dark. But one that absolutely stings  given it distorts actual human face-to-face interactions. Brookers point is that applying digital social management tricksat the pointof flesh and blood contactabsolutely crosses a line. Or to put it another way, its a man in the middle attack on human communications.Another linguistic signifier for technology that is failing to appreciate the nuance of social interaction is the pejorativetermGlasshole  used to brandand mark out for social censure users of Googles (not at all fictional) face computer, Glass.Like the fictional Z-Eyes, Glass is ahybrid device whichuneasily straddles thedigital and physical worlds. The social unease itgenerates has been obvious, and amply explains why consumers have generally shunned it. (And why Google has been forced to have a major rethink.) No one is coining sensitive wordingsuch asgo dark to describe Glass influenceontheir social lives. Becauseconsumers arent allowingit into their lives. The problems inherent withthe technology are writ-large in the language that does, and does not, coalesce around it.Developing products that are not isolated and separated fromtheir social context is the cruxhere. Andthe tl;dr? Linguistic alienation can be a symptom of a far greater disconnect.Listen carefullyto thelanguage your product generatesand it might, as in the case ofall those dating app users flicking thekill switch on matches, flag up potential service stress points. Or even  in the case of Glass and its surface tensionof Glassholes illuminate the antisocial crux of yourabject failure.