Its been a pretty bigweek for tech + privacy, with Apple overhauling the privacy-related info it pushes out to users sharpeningits pro-privacy positioningas a marketing differentiatorfor its devices and services. And NSA whistleblower Edward Snowden stepping into thepublic arenaby joining Twitteras, well, himself  with the verified account status to prove it.(Who knows if Snowdenwas lurking on the service under an assumed name prior to uncloaking as@Snowden. Someone has probably DMed him to ask but he clearly has a big backlog of messages to get through)On the surface the two events may not seem muchrelated but pro-privacy moves by mainstream tech giants can absolutelychart a linkback to Snowdens 2013 revelations about the extent of governmentintelligence agencies dragnet surveillance of the online sphere.Snowdens big reveal crystalized all thosevague yet disconcerting digital sensations prior to then  feelings of being tracked from web service to service, stalked by online ads, and nagging questions about why a simple service needed so much personal data  into the concrete certaintyof the systematicscope and scale of anindustrial surveillance complex with its fingers in all of the mainstream consumer tech platforms. And a private sectoruser-stalkingoperation in the digital business sphere to match.The thing with such gigantic secrets is, once revealed, theres no way they can slink back into the shadows.Its no surprise then thatApples new privacy pages have an entiresection on government information requests in which the companystates categorically:Such public declarations areabsolutely progress. While we cannot know for sure that Apples hardware and software lacks government backdoors, given these are hermetically sealedproprietary products that dont allow an open source route forthird party audits, the company ison the public record with an anti-backdoors statement so haschained itscorporate reputation to thedigital privacy rights cause.Apple isalso making some very clear privacy commitmentsto itsusers. This is also progress.Itsprivacy page states:At Apple, your trust means everything to us. Thats why we respect your privacy and protect it with strong encryption, plus strict policies that govern how all data ishandled.Security and privacy are fundamental to the design of all our hardware, software, and services, including iCloud and new services like Apple Pay. And we continue to make improvements. Two-step verification, which we encourage all our customers to use, in addition to protecting your Apple ID account information, now also protects all of the data you store and keep up to date with iCloud.We believe in telling you up front exactly whats going to happen to your personal information and asking for your permission before you share it with us. And if you change your mind later, we make it easy to stop sharing with us. Every Apple product is designed around those principles. When we do ask to use your data, its to provide you with a better userexperience.Thats not to say that Apples services dont have insecurities  pretty much any software of the modern era contains bugs and flaws that can lead to exploits and data leaks. (Remember last SeptembersiCloud hack?)But the point is one of principle. Apple is making a pro-privacy stance, whichstands in stark contrast to much of the consumer tech industrys wonted ways inrecent times where overreaching T&Cs and vaguely worded privacy policies have all too oftenrequired users to sign over any expectations of privacyfor the privilege of usinga certainservice (even, in some cases, when theyve paid for the service in question  so this is not just a case of privacy being the price of using a free service).Apple making a robust pro-privacy stance sets a new privacy benchmark and puts pressure on those tech business models that have been built on mining personal data in the digital shadows. Of which there are, of course, many. But perhaps things are set to change on that front.Such a high profile company shining a disinfectingspotlight on the value of personal data makes those companies with less clearlyworded privacy commitments seem a whole lot more murky  even if theyre not actually doing anything too outlandish with the data they gather. And whenthere is enough pressure, well some pretty unexciting basematerialscan transforminto something valuable.Apple choosing to champion privacy isa marketing strategy thats bothtimelyand savvy. Of course it aligns with the companyspremium hardware business model. And it allows them to put clearblue water between how they operate and their main, ad-powered competitors big data miningoperations. It also puts them on Snowdens side of the fence; on a principled, public stage, championing the rights of online users not to have their every action data-mined for profit  or fed into Kafka-esquegovernment surveillance apparatus on a ceaseless and hopeless quest for crime-preventing omniscience (Minority Report was fiction, yo).And while Apples own privacy practices should still absolutely be scrutinized  yes its great that they obfuscate your mapping data so they dont have an absolute view of your start and end points, but why are they retaininguser maps data for two years?  they are effectively asking all of us to ask questions about how they operate and what they do with ourdata. To continually hold them to their apparently high standards. And yes, that is progress. Because it applies industry-wide pressure and works to counter the pro-surveillance narrativethat claimsusers dont care about privacy anyway. Bottom line: Plenty of users do care  and certainly they do when you inform them exactly how much invasive snooping is going on. As Snowden has said, we need to have the debate about whats acceptable and whats not  and the simple fact is you cant do that without being fully appraised of the facts.A more cynical view on Apples stance might be that its using privacy as a strategy to shield itselfagainst a relative competitive weakness vs the kinds of big data powered services that companies witha greater overview of their users are able to launch. Google, for instance, has been using user data mined from usage of multiple Google services to power its predictive Google Now feature for several years, touting the convenience of notifications that really know your habits and patterns (because, well, Google reads your emails, knows whats in your calendar, looks at whos in your photos, and so on). With the rise of wearables and a growing Internet of Things, more and more personal data-points can be added to such systems to power apparently more powerful predictions. And yet theres a gigantictrade-off in privacy. The best personal assistant in the world would literally be amind-reader but who would actuallywant to employ such a person? What cost incremental convenience?Meanwhile Apple debutedan update to its Siri voice assistant at its developer conference this summer  called Proactive  which also aims to surface some Google Now-ish predictive smarts. So its also moving towards joining more dots about its users lives. However Apples version of this predictive assistant puts in a privacy check and balance by doing only local on-device processing  meaning its not sucking your personal data into the data-mining cloud to power this feature. So the user gets incremental convenience without an eye-wateringly costlyprivacy price-tag.Thesesorts of pro-privacy, data obfuscating approaches perhaps take more engineering effort to develop. So might be slower to bring to market. They might also be less compelling from a userpoint of view if they arent able to be quite so pin-point accurate  given they are likelyworking with a more partial view of the user, rather than nosing through your emails. But if the user understands the value of their privacy they will also understand the value of a personalized service that does not require they strip entirely naked in order to use it. Apple is betting that tech users will  at the end of the day  prefer to keep theirclothes on.Another thing to note here is that data protection laws vary in different regions.Failure to gain proper consent for how user data is processed is a recurring theme of manyU.S. tech giants doing businessinEurope. Facebook and Google have both faced legal challenges in the regionover such privacy issues. And the Europe Parliamentis in the midst of reworking the blocsdata protection rules with larger penalties for privacy infringements likely coming down the pipe. That might well be another trigger to push tech companies toclean up murky privacypractices. Lurking in the shadows toeschew scrutiny no longer looks a viable strategy in the post-Snowden tech world.Another important development triggered by the Snowden revelations is also coming to a head next week. On Tuesday Europes top court, the ECJ, will rule on whether theSafe Harbor agreement that governs data sharing between Europe and the U.S. affords Europeans enough privacy protections  with the possibility that the court might invalidate the current agreement. U.S. tech companies offeringconsumersservices in Europe but processing user databack in the U.S.rely on this agreement for continued operation of their businesses.The agreement has, in any case, been in defacto crisis ever since Snowden revealed the extent of dragnet government surveillance programs  since the NSA was shown to be hoovering up data from consumer services that were apparently signed up to the privacy covenantof Safe Harbor. How could Europeans personal data shipped across the pond stillbeconsidered safe in an era of systematic mass surveillance by the U.S. government?European privacy campaigner Max Schrems has led a legal challenge on this front, challenging multiple U.S. tech giants for sharing data with the NSA in the Irish court  which referred the case to the ECJ, with adecision now imminent. At the same time,the European Commission is continuing toreview the Safe Harbor agreement with a view to updating the framework giventhe uglyfactof mass surveillance. How exactly they will do that remains to be seen. But the ECJ ruling may overtake the politicians, in any case.In an influentialopinionwritten by the top advisor to the ECJearlier this month, ahead of the courts final decision next week, advocate general Yves Bot argued that U.S. mass surveillance has indeed invalidated the Safe Harbor agreement. Its not clear how the court will rule but they typically lean towardsfollowing the AGs opinion  so at very least these are interesting times for data privacy. Some big implications for how cloud-based techbusinesses operate are in the process of being determined.One thing is amply clear: the privacy debate is here to stay. And for that we mustthank Mr Snowden. Looking ahead, a digital era where users understand the value of personal data and where tech businesses competeto protect  not exploit  privacy sounds pretty exciting to me. Thats the dream.Yes, Mr Snowden, we hear you.Can you hear me now? Edward Snowden (@Snowden) September 29, 2015